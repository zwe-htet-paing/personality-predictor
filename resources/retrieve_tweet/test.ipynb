{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import twitter\n",
    "import lxml.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TWITTER_CONS_KEY = 'uhzOXpxETxaIXRKFmG4J10ztP'\n",
    "TWITTER_CONS_SEC = 'SZBltYRGECF2pJ6t4PMqtRYRGReEFHVam2jxZa97xkJnyiSCki'\n",
    "TWITTER_ACCESS_TOKEN = '1121670465838178304-4MmnwoM6bWS53X7hJwdij5Vsb09emC'\n",
    "TWITTER_ACCESS_SEC = 'BEIZVVAyRNS3kkeeR37ZwyuZ0j2F1uxNV8dAQZTqlK9h2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t = twitter.Api(\n",
    "    consumer_key = TWITTER_CONS_KEY,\n",
    "    consumer_secret = TWITTER_CONS_SEC,\n",
    "    access_token_key = TWITTER_ACCESS_TOKEN, \n",
    "    access_token_secret = TWITTER_ACCESS_SEC,\n",
    "    tweet_mode='extended' # this ensures that we get the full text of the users' original tweets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "screen_name = \"ZweHtet00836419\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the Twitter API using the python-twitter library\n",
    "first_200 = t.GetUserTimeline(screen_name=screen_name, count=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"created_at\": \"Fri Apr 26 07:00:53 +0000 2019\", \"default_profile\": true, \"friends_count\": 10, \"id\": 1121670465838178304, \"id_str\": \"1121670465838178304\", \"name\": \"Zwe Htet Paing\", \"profile_background_color\": \"F5F8FA\", \"profile_image_url\": \"http://pbs.twimg.com/profile_images/1175429557777649664/iKTy6j2Z_normal.jpg\", \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/1175429557777649664/iKTy6j2Z_normal.jpg\", \"profile_link_color\": \"1DA1F2\", \"profile_sidebar_border_color\": \"C0DEED\", \"profile_sidebar_fill_color\": \"DDEEF6\", \"profile_text_color\": \"333333\", \"profile_use_background_image\": true, \"screen_name\": \"ZweHtet00836419\", \"status\": {\"created_at\": \"Fri Sep 20 12:03:36 +0000 2019\", \"full_text\": \"Teamwork making the dream work in the UEFA Champions League... Some things never change. \\ud83e\\udd29 But which was your fav\\u2026 https://t.co/ZgN0yCkXlr\", \"id\": 1175017663644364806, \"id_str\": \"1175017663644364806\", \"lang\": \"en\", \"source\": \"<a href=\\\"https://mysite.com\\\" rel=\\\"nofollow\\\">Personality Prediction using SVM</a>\"}, \"statuses_count\": 3}\n"
     ]
    }
   ],
   "source": [
    "print(t.VerifyCredentials())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 tweets in our dataset, which has the type <class 'list'>.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"There are %d tweets in our dataset, which has the type %s.\" % (len(first_200), type(first_200)))\n",
    "print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a sample of what the data from one tweet looks like:\n",
      "{\"created_at\": \"Fri Sep 20 12:03:36 +0000 2019\", \"full_text\": \"Teamwork making the dream work in the UEFA Champions League... Some things never change. \\ud83e\\udd29 But which was your fav\\u2026 https://t.co/ZgN0yCkXlr\", \"hashtags\": [], \"id\": 1175017663644364806, \"id_str\": \"1175017663644364806\", \"lang\": \"en\", \"source\": \"<a href=\\\"https://mysite.com\\\" rel=\\\"nofollow\\\">Personality Prediction using SVM</a>\", \"urls\": [{\"expanded_url\": \"https://twitter.com/i/web/status/1175005610762473472\", \"url\": \"https://t.co/ZgN0yCkXlr\"}], \"user\": {\"created_at\": \"Fri Apr 26 07:00:53 +0000 2019\", \"default_profile\": true, \"friends_count\": 10, \"id\": 1121670465838178304, \"id_str\": \"1121670465838178304\", \"name\": \"Zwe Htet Paing\", \"profile_background_color\": \"F5F8FA\", \"profile_image_url\": \"http://pbs.twimg.com/profile_images/1175429557777649664/iKTy6j2Z_normal.jpg\", \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/1175429557777649664/iKTy6j2Z_normal.jpg\", \"profile_link_color\": \"1DA1F2\", \"profile_sidebar_border_color\": \"C0DEED\", \"profile_sidebar_fill_color\": \"DDEEF6\", \"profile_text_color\": \"333333\", \"profile_use_background_image\": true, \"screen_name\": \"ZweHtet00836419\", \"statuses_count\": 3}, \"user_mentions\": []}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Here's a sample of what the data from one tweet looks like:\")\n",
    "print(first_200[0])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each tweet is stored in a <class 'twitter.models.Status'> data structure.\n"
     ]
    }
   ],
   "source": [
    "print(\"Each tweet is stored in a %s data structure.\" % type(first_200[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(first_200, screen_name, last_id):\n",
    "    all_tweets = []\n",
    "    all_tweets.extend(first_200)\n",
    "    for i in range(900):\n",
    "        new = t.GetUserTimeline(screen_name=screen_name, max_id=last_id-1)\n",
    "        if len(new) > 0:\n",
    "            all_tweets.extend(new)\n",
    "            last_id = new[-1].id\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return all_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets = get_tweets(first_200, screen_name, first_200[-1].id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 tweets stored in a list as the all_tweets variable.\n",
      "The most recent tweet in our collection was sent Fri Sep 20 12:03:36 +0000 2019 and the oldest tweet was sent Fri Sep 20 12:02:28 +0000 2019.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are %d tweets stored in a list as the all_tweets variable.\" % len(all_tweets))\n",
    "print(\"The most recent tweet in our collection was sent %s and the oldest tweet was sent %s.\" % (\n",
    "                                                                            all_tweets[0].created_at, \n",
    "                                                                            all_tweets[-1].created_at)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"created_at\": \"Fri Sep 20 12:03:36 +0000 2019\", \"full_text\": \"Teamwork making the dream work in the UEFA Champions League... Some things never change. \\ud83e\\udd29 But which was your fav\\u2026 https://t.co/ZgN0yCkXlr\", \"hashtags\": [], \"id\": 1175017663644364806, \"id_str\": \"1175017663644364806\", \"lang\": \"en\", \"source\": \"<a href=\\\"https://mysite.com\\\" rel=\\\"nofollow\\\">Personality Prediction using SVM</a>\", \"urls\": [{\"expanded_url\": \"https://twitter.com/i/web/status/1175005610762473472\", \"url\": \"https://t.co/ZgN0yCkXlr\"}], \"user\": {\"created_at\": \"Fri Apr 26 07:00:53 +0000 2019\", \"default_profile\": true, \"friends_count\": 10, \"id\": 1121670465838178304, \"id_str\": \"1121670465838178304\", \"name\": \"Zwe Htet Paing\", \"profile_background_color\": \"F5F8FA\", \"profile_image_url\": \"http://pbs.twimg.com/profile_images/1175429557777649664/iKTy6j2Z_normal.jpg\", \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/1175429557777649664/iKTy6j2Z_normal.jpg\", \"profile_link_color\": \"1DA1F2\", \"profile_sidebar_border_color\": \"C0DEED\", \"profile_sidebar_fill_color\": \"DDEEF6\", \"profile_text_color\": \"333333\", \"profile_use_background_image\": true, \"screen_name\": \"ZweHtet00836419\", \"statuses_count\": 3}, \"user_mentions\": []}\n"
     ]
    }
   ],
   "source": [
    "print(all_tweets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data in the created_at attribute looks like this: Fri Sep 20 12:03:14 +0000 2019\n",
      "Data in the hashtags attribute looks like this: []\n",
      "Data in the urls attribute looks like this: []\n",
      "Data in the source attribute looks like this: <a href=\"https://mysite.com\" rel=\"nofollow\">Personality Prediction using SVM</a>\n"
     ]
    }
   ],
   "source": [
    "print(\"Data in the created_at attribute looks like this:\", all_tweets[1].created_at)\n",
    "print(\"Data in the hashtags attribute looks like this:\", all_tweets[1].hashtags)\n",
    "print(\"Data in the urls attribute looks like this:\", all_tweets[1].urls)\n",
    "print(\"Data in the source attribute looks like this:\", all_tweets[1].source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_hashtags(hashtags):\n",
    "    \"\"\"\n",
    "    Turns data with any number of hashtags like this - [Hashtag(Text='STEMonStation')] - to a list like this -\n",
    "    ['STEMonStation']\n",
    "    \"\"\"\n",
    "    cleaned = []\n",
    "    if len(hashtags) >= 1:\n",
    "        for i in range(len(hashtags)):\n",
    "            cleaned.append(hashtags[i].text)        \n",
    "    return cleaned\n",
    "\n",
    "def clean_urls(urls):\n",
    "    \"\"\"\n",
    "    Turns data with any number of expanded urls like this - \n",
    "    [URL(URL=https://t.co/sYCFHKxzBf, ExpandedURL=https://youtu.be/34bFgA3H3hQ)]- to a list like this - \n",
    "    [\"https://youtu.be/34bFgA3H3hQ\"]\n",
    "    \"\"\"\n",
    "    cleaned = []\n",
    "    if len(urls) >= 1:\n",
    "        for i in range(len(urls)):\n",
    "            cleaned.append(urls[i].expanded_url)\n",
    "    return(cleaned)\n",
    "        \n",
    "\n",
    "def clean_source(source):\n",
    "    \"\"\"\n",
    "    Turns data including the source and some html like this - \n",
    "    <a href=\"https://www.sprinklr.com\" rel=\"nofollow\">Sprinklr</a> - to a list like this -\n",
    "    ['Sprinklr']\n",
    "    \"\"\"\n",
    "    raw = lxml.html.document_fromstring(source)\n",
    "    return raw.cssselect('body')[0].text_content()\n",
    "\n",
    "\n",
    "def string_to_datetime(date_str):\n",
    "    \"\"\"\n",
    "    Turns a string including date and time like this - Sun Jul 01 21:06:07 +0000 2018 - to a Python datetime object\n",
    "    like this - datetime.datetime(2018, 7, 1, 21, 6, 7, tzinfo=datetime.timezone.utc)\n",
    "    \"\"\"\n",
    "    return datetime.strptime(date_str, '%a %b %d %H:%M:%S %z %Y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(tweets, filename):\n",
    "    # the headers are the fields that we identified in step 4\n",
    "    #headers = ['id', 'full_text', 'hashtags', 'urls', 'created_at', 'favorite_count', 'retweet_count', 'source']\n",
    "    headers = ['id','full_text','source']\n",
    "    \n",
    "    # here we create the file and write the header row with the headers list\n",
    "    # note that the 'filename' argument will be the name of the csv file\n",
    "    with open(filename + '.csv', 'w', newline='',encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow(headers)\n",
    "        \n",
    "        # in this loop, we write a new row for each tweet object, with the data taken from the tweet object in \n",
    "        # the order we listed the headers\n",
    "        # note where we call the helper functions from step 4 on hashtags, urls, and source\n",
    "        for item in tweets:\n",
    "            writer.writerow([item.id, \n",
    "                             item.full_text, \n",
    "                             #clean_hashtags(item.hashtags), \n",
    "                             #clean_urls(item.urls), \n",
    "                             #item.created_at, \n",
    "                             #item.favorite_count, \n",
    "                             #item.retweet_count, \n",
    "                             clean_source(item.source)])\n",
    "    csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data(tweets):\n",
    "    X=[]\n",
    "    for item in tweets:\n",
    "        X.append(item.full_text)\n",
    "    return X\n",
    "\n",
    "X = test_data(first_200)\n",
    "Y = test_data(all_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Teamwork making the dream work in the UEFA Champions League... Some things never change. 🤩 But which was your fav… https://t.co/ZgN0yCkXlr', '😍 An elegant artist with a touch of genius... 🇧🇬 Happy retirement, Dimitar Berbatov', 'hello my name is Zwe Htet Paing and I love betting football match.']\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Teamwork making the dream work in the UEFA Champions League... Some things never change. 🤩 But which was your fav… https://t.co/ZgN0yCkXlr', '😍 An elegant artist with a touch of genius... 🇧🇬 Happy retirement, Dimitar Berbatov', 'hello my name is Zwe Htet Paing and I love betting football match.']\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_csv(first_200, screen_name + '_tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(screen_name + '_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZweHtet00836419_tweets.csv\n"
     ]
    }
   ],
   "source": [
    "filename =screen_name + '_tweets.csv'\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict(tweets):\n",
    "    dict = {}\n",
    "    for item in tweets:\n",
    "        clean_source(item.source)\n",
    "        dict[item.id_str] = {\n",
    "            'full_text': item.full_text,\n",
    "            #'hashtags': clean_hashtags(item.hashtags),\n",
    "            #'urls': clean_urls(item.urls),\n",
    "            #'created_at': string_to_datetime(item.created_at),\n",
    "            #'favorite_count': item.favorite_count,\n",
    "            #'retweet_count' : item.retweet_count,\n",
    "            'source': clean_source(item.source)\n",
    "        }\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_dict = create_dict(all_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_dict['1172908785582497792']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweet_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.4955237907970503*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
